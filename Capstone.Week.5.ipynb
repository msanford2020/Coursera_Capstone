{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<H1>Exploring the Austin Texas Area<H1>"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<H2><H2>Libraries"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Importing the libraries needed to get started. \nimport sys\n!{sys.executable} -m pip install geocoder\n!{sys.executable} -m pip install folium\n!pip install lxml\n!pip install uszipcode\n!pip install beautifulsoup4\n\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n!conda install -c conda-forge geopy --yes # uncomment this line if you haven't completed the Foursquare API lab\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\nimport pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\nimport json # library to handle JSON files\n\n\nimport pandas as pd\nimport numpy as np\nimport requests\nimport json\nfrom bs4 import BeautifulSoup\nimport re\nfrom geopy.geocoders import Nominatim\nimport pprint\nimport folium\nfrom folium.features import DivIcon\nfrom folium import IFrame\nimport matplotlib.pyplot as plt\nfrom IPython.display import display\nfrom sklearn.cluster import KMeans\nfrom uszipcode import SearchEngine\nfrom uszipcode import Zipcode\nfrom pandas.io.json import json_normalize\nimport pandas as pd \nimport numpy as np\nimport requests\nprint('Libraries imported.')\n\n# Four Square credentials\nclient_id = 'P0MEEIQBEYLE2ZANW1HBPQCG150PIQA4OQUBPWBTQIUDDMXT'\nclient_secret = 'RGWBZJNJD2C12JE45VGZTRARXGUBKQS41YPBGI4U2NNLLEUE'\nversion = '20180605'\n\n# Zillow ZWSID\nzwsid = \"X1-ZWz174hlm3pybv_2ox88\"\n\n# OpenCage Geocoding API key\nmy_api_key = \"ffa7f2d7f52241e89950f04f26c095d2\""
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<H2><H2>Credentials for Foursquare zillow and opencage geocoding"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Four Square credentials\nclient_id = 'P0MEEIQBEYLE2ZANW1HBPQCG150PIQA4OQUBPWBTQIUDDMXT'\nclient_secret = 'RGWBZJNJD2C12JE45VGZTRARXGUBKQS41YPBGI4U2NNLLEUE'\nversion = '20180605'\n\n# Zillow ZWSID\nzwsid = \"X1-ZWz174hlm3pybv_2ox88\"\n\n# OpenCage Geocoding API key\nmy_api_key = \"ffa7f2d7f52241e89950f04f26c095d2\""
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<H2><H2> Looking at the Austin area for most populated cities to explore."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Using wikipedia to get the city information. \naustin_nearby = \"https://en.wikipedia.org/wiki/Greater_Austin\"\nresponse = requests.get(austin_nearby)\n\n# BeautifulSoup to Parse\nsoup = BeautifulSoup(response.text, \"html.parser\")\ntable = soup.find_all(\"table\", class_=\"wikitable\")\npopulation_table = table[1]\npop_def = population_table.find_all('td')\n\ncity_list = []\npopulation_list = []\n\n#looking for the top 5:\nfor i in range(0, 16, 3):\n    city_list.append(pop_def[i].text.strip())\n    population_list.append(pop_def[i+1].contents[0])\n\ncity_df = pd.DataFrame(columns=[\"CityName\", \"Population\"])\ncity_df[\"CityName\"] = city_list \ncity_df[\"Population\"] = population_list\ncity_df"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<H3> Top 3 cities with latitude and longitude using opencage"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Top 3 with latitude and Longitude.\ncity_list = ['Austin', 'Round Rock', 'Georgetown']\nlatitude_list = []\nlongitude_list = []\ntop_city_df = pd.DataFrame(columns=[\"CityName\", \"Population\", \"Latitude\", \"Longitude\"])\n\nfor city in city_list:\n    query = city + \", TX, United States of America\"\n    uri = \"https://api.opencagedata.com/geocode/v1/json?q={}&key={}\".format(query, my_api_key)\n    response = requests.get(uri).json()\n    latitude_list.append(response['results'][0]['geometry']['lat'])\n    longitude_list.append(response['results'][0]['geometry']['lng'])\n    \ntop_city_df[\"CityName\"] = city_list\ntop_city_df[\"Latitude\"] = latitude_list\ntop_city_df[\"Population\"] = city_df[\"Population\"]\ntop_city_df[\"Longitude\"] = longitude_list\n    \ntop_city_df\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<H3> Median home value for all three cities covering 2019, 2020 and forecast for 2021."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Using payload for the analysis.\nreq_headers = {\n    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n    'accept-encoding': 'gzip, deflate, br',\n    'accept-language': 'en-US,en;q=0.8',\n    'upgrade-insecure-requests': '1',\n    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'\n}\n\nmedian_values = []\nlast_change = []\nforecast = []\n\ncities = [\"Austin\", \"Round-rock\", \"Georgetown\"]\nfor city in cities:\n    url = \"https://www.zillow.com/{}-tx/home-values/\".format(city)\n    response = requests.get(url, headers=req_headers)\n    soup = BeautifulSoup(response.content, 'html.parser')\n    median = soup.find_all('h2')\n    median_values.append(median[0].text)\n    \n    change_list = soup.find_all('ul', class_='zsg-g')\n    list_item = change_list[0].find_all('li')\n    last_change.append(list_item[0].text)    \n    forecast.append(list_item[1].text.strip())\n    \nhome_value_dataframe = pd.DataFrame(columns=[\"City\", \"Last Year Value\", \"Current Median Value\", \"Next Year Forecast\"])\nhome_value_dataframe[\"City\"] = cities\nhome_value_dataframe[\"Last Year Value\"] = last_change\nhome_value_dataframe[\"Current Median Value\"] = median_values\nhome_value_dataframe[\"Next Year Forecast\"] = forecast\n\nhome_value_dataframe"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Need to create two lists to parse.\n\nnew_ly_values = []\nnew_fc_values = []\n\n# regex pattern to clean up the data\npercentage_regex = re.compile(r'\\d+.\\d+%')\n\n# parsing through to match regex and adding it to the lists mentioned above.\nfor values in home_value_dataframe['Last Year Value']:\n    sliced_value = percentage_regex.search(values)\n    new_ly_values.append(sliced_value.group())\n\nfor values in home_value_dataframe['Next Year Forecast']:\n    sliced_value = percentage_regex.search(values)\n    new_fc_values.append(sliced_value.group())\n\nhome_value_dataframe[\"Last Year Value\"] = new_ly_values\nhome_value_dataframe[\"Next Year Forecast\"] = new_fc_values\nhome_value_dataframe['Current Median Value'] = home_value_dataframe['Current Median Value'].str.replace(\"$\", \"\")\nhome_value_dataframe['Current Median Value'] = home_value_dataframe['Current Median Value'].str.replace(\",\", \"\")\n\n\nhome_value_dataframe"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "home_value_dataframe['Last Year Value'] = home_value_dataframe['Last Year Value'].str.replace(\"%\",\"\")\nhome_value_dataframe['Next Year Forecast'] = home_value_dataframe['Next Year Forecast'].str.replace(\"%\",\"\")\n\nfor i in range(len(home_value_dataframe)):\n    last_percent = float(home_value_dataframe.loc[i, 'Last Year Value'])\n    forecast = float(home_value_dataframe.loc[i, 'Next Year Forecast'])\n    median_value = float(home_value_dataframe.loc[i, 'Current Median Value'])\n    \n    last = float(last_percent/100)\n    fore = float(forecast/100)\n    home_value_dataframe.loc[i, 'Last Year Value'] = (1 - last) * median_value\n    home_value_dataframe.loc[i, 'Next Year Forecast'] = (1 + fore) * median_value\n\n\nhome_value_dataframe"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<H3>Providing one consoidated view of the findings using the methodology and data."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import matplotlib.pyplot as plt\nplt.style.use('classic')\nimport numpy as np\nfrom pandas import Series, DataFrame\n \n# plotting the health venues in three cities for easier comparison\ndata = [401999, 380291, 79604]\nlabels = [\"Austin\",\"Round Rock\", \"Georgetown\"]\nwidth = .25\nplt.xticks(range(len(data)), labels, fontsize=14)\nplt.xlabel('City',fontsize=14)\nplt.ylabel('Median Price')\nplt.title(\"Current Median comparison\")\nplt.xticks(range(len(data)), labels)\nplt.bar(range(len(data)), data, width=width, color= 'blue') \n\nplt.show() \n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<H3> Providing three individual views for a comparison within each city."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Austin Median Compare\nimport matplotlib.pyplot as plt\nplt.style.use('classic')\nimport numpy as np\nfrom pandas import Series, DataFrame\n  \n\nplt.rcParams['axes.facecolor']='lightblue'\nplt.rcParams['savefig.facecolor']='lightblue'\n\n\nx = [2019, 2020, 2021]\ny = [380291,401990,404810]\n\nmy_xticks = ['2019', '2020', '2021']\nplt.figure(figsize=(7,6))\n\nplt.xticks(x, my_xticks, fontsize=14)\nplt.yticks(fontsize=12)\n\nplt.title(\"Austin Median Price 2019-2021\", fontsize=16, color = 'black')\nplt.plot(x , y, 'b-o',color ='red')\nfor a, b in zip(x, y):\n    val = \"$\" + str(b)\n    plt.text(a+0.08, b, val, fontsize=15, color='red' )\n        "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Round rock median compare\nimport matplotlib.pyplot as plt\nplt.style.use('classic')\nimport numpy as np\nfrom pandas import Series, DataFrame\n  \n\nplt.rcParams['axes.facecolor']='lightblue'\nplt.rcParams['savefig.facecolor']='lightblue'\n\n\nx = [2019, 2020, 2021]\ny = [299162, 302184,312458]\n\nmy_xticks = ['2019', '2020', '2021']\nplt.figure(figsize=(7,6))\n\nplt.xticks(x, my_xticks, fontsize=14)\nplt.yticks(fontsize=12)\n\nplt.title(\"Round Rock Median Price 2019-2021\", fontsize=16, color = 'black')\nplt.plot(x , y, 'b-o',color ='red')\nfor a, b in zip(x, y):\n    val = \"$\" + str(b)\n    plt.text(a+0.08, b, val, fontsize=15, color='red' )"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Georgetown median compare\nimport matplotlib.pyplot as plt\nplt.style.use('classic')\nimport numpy as np\nfrom pandas import Series, DataFrame\n  \nx = [2019, 2020, 2021]\ny = [299162, 302184,312458]\nplt.rcParams['axes.facecolor']='lightblue'\nplt.rcParams['savefig.facecolor']='lightblue'\n\nmy_xticks = ['2019', '2020', '2021']\nplt.figure(figsize=(7,6))\n\nplt.xticks(x, my_xticks, fontsize=12)\nplt.yticks(fontsize=12)\nplt.title(\"Georgetown Median Price 2019-2021\", fontsize=16, color = 'black')\nplt.plot(x , y, 'b-o',color ='red')\nfor a, b in zip(x, y):\n    val = \"$\" + str(b)\n    plt.text(a+0.08, b, val, fontsize=15, color='red' )"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<H2> Exploring the housing prices based on median values"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<H3>Looking for the median household income leveraging zipmaps "
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Getting zip codes of austin for the search\n\naustin_zip = \"http://www.city-data.com/zipmaps/Austin-Texas.html\"\nresponse = requests.get(austin_zip)\nziplist = []\n# Parsing the results with BeautifulSoup\nsoup = BeautifulSoup(response.text, \"html.parser\")\ntable = soup.find_all('div', class_=\"zip data-block\")\nfor t in table:\n    ziplist.append(t[\"id\"])\n    \n# sample ziplist of Austin\nziplist[0:10]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# cleaning the dataframe \n# setting the search engine\nsearch = SearchEngine(simple_zipcode=True)\nresults = []\nfor z in ziplist:\n    zipcode = search.by_zipcode(z)\n    data = zipcode.to_dict()\n    results.append(data)\n\n# storing the results in a dataframe    \naustin_zip_df = json_normalize(results)\naustin_zip_df.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# narrowing columns for analysis\naustin_zip_df = austin_zip_df.drop(['bounds_east', 'bounds_north', 'bounds_south', 'area_code_list', 'common_city_list', 'population_density', 'bounds_west', 'major_city', 'post_office_city', 'state', 'timezone', 'zipcode_type'], 1)\naustin_zip_df.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# cleaning the dataframe a bit to make it more readable and usable\naustin_zip_df['county'] = austin_zip_df['county'].str.replace(\"County\",\"\")\nzipcol = austin_zip_df['zipcode']\naustin_zip_df.drop('zipcode', axis=1,inplace=True)\naustin_zip_df.insert(0, 'zipcode', zipcol)\n\naustin_zip_df.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# one-hot encoding the county names\ncounty_dummies = pd.get_dummies(austin_zip_df['county'], prefix='county')\naustin_df = pd.concat([austin_zip_df, county_dummies], axis=1)\naustin_df = austin_df.drop('county', 1)\naustin_df.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# set the number of clusters\nk = 3\n\n# running K-Means clustering\nkmeans = KMeans(n_init=400, n_clusters=k, random_state=1).fit(austin_df)\nkmeans.labels_\n\n# adding the cluster labels to the dataframe\naustin_df.insert(0, 'Cluster', kmeans.labels_)\naustin_df.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# examining each cluster\ncluster_one = austin_df[austin_df.Cluster == 0]\ncluster_one.sort_values(\"median_home_value\", axis = 0, ascending = True, inplace = True) \ncluster_one"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "cluster_two = austin_df[austin_df.Cluster == 1]\ncluster_two.sort_values(\"median_home_value\", axis = 0, ascending = True, inplace = True) \ncluster_two"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "cluster_three = austin_df[austin_df.Cluster == 2]\ncluster_three.sort_values(\"median_home_value\", axis = 0, ascending = True, inplace = True) \ncluster_three"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<H2> Home prices in the above clusters provide buyers insight into home pricing:"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<H4>Cluster One = 72k-237k\n<H4>Cluster Two = 247-442k\n<H4>Cluster Three = 460k-641k"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<H3>Analysis provides answer to those that have a price range in which they are seeking to stay within. "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Leveraging FourSquare's API to explore Austin, Round Rock and Georgetown."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Four Square credentials\nclient_id = 'P0MEEIQBEYLE2ZANW1HBPQCG150PIQA4OQUBPWBTQIUDDMXT'\nclient_secret = 'RGWBZJNJD2C12JE45VGZTRARXGUBKQS41YPBGI4U2NNLLEUE'\nversion = '20180605'"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# defining a class to to explore venues under various categories\ndef requestPayload(latitude, longitude, category):\n    # crafting the request url\n    limit = 500      # no. of locations to return\n    radius = 8050    # approx 5 miles\n    url = \"https://api.foursquare.com/v2/venues/search?categoryId={}&client_id={}&client_secret={}&v={}&limit={}&radius={}&ll={},{}\".format(category, client_id, client_secret, version, limit, radius, latitude, longitude)\n    return url "
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Leveraging categories in foursquare to provide schools in each area."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### 1. Schools"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Category list that with category IDs of different schools\nschools_list = [\n    \"4d4b7105d754a06372d81259\", \"4f4533804b9074f6e4fb0105\", \"4f4533814b9074f6e4fb0106\", \n    \"4bf58dd8d48988d13d941735\", \"52e81612bcbc57f1066b7a45\"]\n\n\n# creating an empty dataframe to store the results\nschools_dataframe = pd.DataFrame(columns=[\"CityName\", \"Venue\", \"Latitude\", \"Longitude\"])\nvenues_list = []\ncategory_list =[]\ncategory_type =[]\nlatitude_list = []\nlongitude_list = []\ncity_list = []\n\nfor city in range(3):\n    for category in schools_list:\n        response = requests.get(requestPayload(top_city_df.loc[city, \"Latitude\"], top_city_df.loc[city, \"Longitude\"], category)).json()\n        for i in range(len(response['response']['venues'])):\n            category_list.append(response['response']['venues'][i]['name'])\n            category_type.append(response['response']['venues'][i]['name'])\n            venues_list.append(response['response']['venues'][i]['name'])\n            latitude_list.append(response['response']['venues'][i]['location']['lat'])\n            longitude_list.append(response['response']['venues'][i]['location']['lng'])\n            city_list.append(top_city_df.loc[city, \"CityName\"])\n            \nschools_dataframe[\"CityName\"] = city_list\nschools_dataframe[\"Venue\"] = venues_list\nschools_dataframe[\"category\"]= category_list\nschools_dataframe[\"cattype\"]= category_type\nschools_dataframe[\"Latitude\"] = latitude_list\nschools_dataframe[\"Longitude\"] = longitude_list"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "schools_dataframe.to_csv(r'c:\\users\\msanford\\schools.csv')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Schools \n\nax = schools_dataframe['CityName'].value_counts().plot(kind='bar', figsize=(8,6), fontsize=12, color='purple')\nax.set_xlabel(\"City\", fontsize=14)\nplt.xticks(rotation=0)\nax.set_ylabel(\"# of Schools\", fontsize=14)\nplt.title(\"Schools in Austin, Round Rock & Georgetown\", fontsize=15)\n\nfor i in ax.patches:\n    ax.text(i.get_x()+.17, i.get_height()+0.6, str(i.get_height()), fontsize=14)\n\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Leveraging categories in foursquare to provide schools available."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Grouping the categories"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "summary = schools_dataframe.groupby('CityName').count().reset_index()\nsummary['Count'] = summary['Venue']\nsummary = summary.drop(['Latitude', 'Longitude', 'Venue', 'category'], axis=1)\nsummary = summary.sort_values('Count').reset_index(drop=True)\nsummary.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### 2. Food"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Food\nfood_list = [\n    \"4d4b7105d754a06374d81259\", \"4bf58dd8d48988d14e941735\", \"4bf58dd8d48988d142941735\", \"4bf58dd8d48988d111941735\", \n\"4bf58dd8d48988d113941735\", \"4eb1d5724b900d56c88a45fe\", \"4bf58dd8d48988d1d1941735\", \"4bf58dd8d48988d149941735\", \n\"4bf58dd8d48988d1df931735\", \"4bf58dd8d48988d143941735\", \"4bf58dd8d48988d16d941735\", \"4bf58dd8d48988d1e0931735\", \n \"4bf58dd8d48988d147941735\", \"4bf58dd8d48988d16e941735\"]\n\n# creating an empty dataframe to store the results\nfood_dataframe = pd.DataFrame(columns=[\"CityName\", \"Venue\", \"Latitude\", \"Longitude\"])\nvenues_list = []\ncategory_list =[]\ncategory_type=[]\nlatitude_list = []\nlongitude_list = []\ncity_list = []\n\nfor city in range(3):\n    for category in food_list:\n        response = requests.get(requestPayload(top_city_df.loc[city, \"Latitude\"], top_city_df.loc[city, \"Longitude\"], category)).json()\n        for i in range(len(response['response']['venues'])):\n            venues_list.append(response['response']['venues'][i]['name'])\n            category_list.append(response['response']['venues'][i]['name'])\n            category_type.append(response['response']['venues'][i]['name'])\n            latitude_list.append(response['response']['venues'][i]['location']['lat'])\n            longitude_list.append(response['response']['venues'][i]['location']['lng'])\n            city_list.append(top_city_df.loc[city, \"CityName\"])\n            \nfood_dataframe[\"CityName\"] = city_list\nfood_dataframe[\"Venue\"] = venues_list\nfood_dataframe[\"category\"]= category_list\nfood_dataframe[\"Latitude\"] = latitude_list\nfood_dataframe[\"cattype\"]= category_type\nfood_dataframe[\"Longitude\"] = longitude_list\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Food\nfood_list = [\n    \"4d4b7105d754a06374d81259\", \"4bf58dd8d48988d14e941735\", \"4bf58dd8d48988d142941735\", \"4bf58dd8d48988d111941735\", \n\"4bf58dd8d48988d113941735\", \"4eb1d5724b900d56c88a45fe\", \"4bf58dd8d48988d1d1941735\", \"4bf58dd8d48988d149941735\", \n\"4bf58dd8d48988d1df931735\", \"4bf58dd8d48988d143941735\", \"4bf58dd8d48988d16d941735\", \"4bf58dd8d48988d1e0931735\", \n \"4bf58dd8d48988d147941735\", \"4bf58dd8d48988d16e941735\"]\n\n# creating an empty dataframe to store the results\nfood_dataframe = pd.DataFrame(columns=[\"CityName\", \"Venue\", \"Latitude\", \"Longitude\"])\nvenues_list = []\ncategory_list =[]\ncategory_type=[]\nlatitude_list = []\nlongitude_list = []\ncity_list = []\n\nfor city in range(3):\n    for category in food_list:\n        response = requests.get(requestPayload(top_city_df.loc[city, \"Latitude\"], top_city_df.loc[city, \"Longitude\"], category)).json()\n        for i in range(len(response['response']['venues'])):\n            venues_list.append(response['response']['venues'][i]['name'])\n            category_list.append(response['response']['venues'][i]['name'])\n            category_type.append(response['response']['venues'][i]['name'])\n            latitude_list.append(response['response']['venues'][i]['location']['lat'])\n            longitude_list.append(response['response']['venues'][i]['location']['lng'])\n            city_list.append(top_city_df.loc[city, \"CityName\"])\n            \nfood_dataframe[\"CityName\"] = city_list\nfood_dataframe[\"Venue\"] = venues_list\nfood_dataframe[\"category\"]= category_list\nfood_dataframe[\"Latitude\"] = latitude_list\nfood_dataframe[\"cattype\"]= category_type\nfood_dataframe[\"Longitude\"] = longitude_list\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "food_dataframe.to_csv(r'c:\\users\\msanford\\food.csv')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Food venues \nax = food_dataframe['CityName'].value_counts().plot(kind='bar', figsize=(8,6), fontsize=12, color='pink')\nax.set_xlabel(\"City\", fontsize=14)\nplt.xticks(rotation=0)\nax.set_ylabel(\"# of Venues\", fontsize=12)\nplt.title(\"Food Venues in Austin, Round Rock & Georgetown\", fontsize=15)\n\nfor i in ax.patches:\n    ax.text(i.get_x()+.17, i.get_height()+4.0, str(i.get_height()), fontsize=14)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Leveraging categories in foursquare to provide food vendues available."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### Grouping for count"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "summary = food_dataframe.groupby('CityName').count().reset_index()\nsummary['Count'] = summary['Venue']\nsummary = summary.drop(['Latitude', 'Longitude', 'Venue', 'category'], axis=1)\nsummary = summary.sort_values('Count').reset_index(drop=True)\nsummary.head()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<H2> Map of the food and school venues in Austin"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Combining all different venue categories of Austin into a single dataframe\naustin_dataframe = pd.concat([\n    \n    food_dataframe[food_dataframe.CityName == \"Austin\"],\n    schools_dataframe[schools_dataframe.CityName == \"Austin\"]],ignore_index=True)\n\nprint(austin_dataframe.shape)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Map of all these Austin venues into a map\naustin_map = folium.Map(location=[30.271129, -97.743700], zoom_start=11)\n\n# adding markers\nfor lat, lng, venue in zip(austin_dataframe['Latitude'], austin_dataframe['Longitude'], austin_dataframe['Venue']):\n    label = \"\".format(venue)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=4,\n        popup=label,\n        color='red',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.3,\n        parse_html=False).add_to(austin_map)\n\n# Austin with all category venues plotted\naustin_map"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<H2>Results and Conclusion"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<H5>Austin and the surrounding areas, the three cities, Austin, Round Rock, Georgetown were the most populated.\n<H5>Austin has a very good pricing range and is a good choice for a home buyer. \n<H5>This result was proven with the number of schools, food venues, home values and forecasting analysis and data.  \n<H5>The projected forecast for the median home in Austin was clearly proved to be on the rise in the next year.  \n<H5>The clustering and grouping of the data sets and methodologies noted led to some insight that is supported by the data itself.   \n\n<H2>It\u2019s a great spot to call home and work remotely!  \n"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python",
            "language": "python",
            "name": "conda-env-python-py"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}